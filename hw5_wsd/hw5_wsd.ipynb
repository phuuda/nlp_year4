{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДЗ 5: WSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Код - здесь ниже\n",
    "* Vectorizers: Count, Tf/idf\n",
    "* Classifiers: multinomial naive Bayes, Random Forest, Decision Tree\n",
    "\n",
    "#### 2) Данные:\n",
    "https://github.com/phuuda/nlp_year4/blob/master/hw5_wsd/castle-lock.txt <br><br>\n",
    "\n",
    "Данные + 10 собственных примеров:<br>\n",
    "https://github.com/phuuda/nlp_year4/blob/master/hw5_wsd/test_contexts.txt\n",
    "\n",
    "#### 3) Описание:\n",
    "\n",
    "Данные:\n",
    "\n",
    "<b>а.</b> Source: Sketch Engine, ruTenTen11, lemma searched = 'замок'\n",
    "\n",
    "<b>б.</b><br>\n",
    "* 700 контекстов употребления 'замок' = castle -- class 1\n",
    "* 700 контекстов употребления 'замок' = lock -- class 0\n",
    "* тексты ruTenTen11 -- из интернета\n",
    "* значение лексемы в каждом примере размечалось вручную\n",
    "* контексты -- примено 10-15 слов\n",
    "\n",
    "<b>в.</b><br>\n",
    "* лемматизатор -- Mystem\n",
    "* стоп-лист -- расширенный список на основе Вордстата: http://www.bukvarix.com/bukvarix-stop-words.html<br>\n",
    "\n",
    "<b>г.</b> примеры ошибок для модели <b>Initial vectors + Random Forest + Tf idf</b>:<br>\n",
    "* <i>ночью замок был освещен и был открыт для посетителей и ночных экскурсий</i> (неясно, почему ошибочно классифицирует как 'lock'. видимо, не достаточно key-words про средневековье (<i>рыцари</i>, <i>старинный</i>, <i>королевский</i>, etc.))\n",
    "* <i>ребенок пытался вставить карандаш в скважину и громко орал</i> (тоже не очень ясно, видимо из-за отсутствия слов <i>дверь</i>, <i>ключ</i>, <i>металл</i>, and similar.)\n",
    "\n",
    "<b>д.</b> таблица с результатами по 6 моделям:<br>\n",
    "<img src=\"https://raw.githubusercontent.com/phuuda/nlp_year4/master/hw5_wsd/hw5_wsd_results.png\"><br>\n",
    "\n",
    "* Для initial & reduced vectors Pipeline давал estimation, что <b>naive Bayes</b> + Count Vectorizer выдаст наибольший accuracy (89% и 82% respectively)<br><br>\n",
    "\n",
    "* Для reduced vectors это частично подтвердилось: <b>Bayes</b> выдавал наибольший accuracy of classification, совпадающий у Tf/idf & Count Vectorizers (85%).<br><br>\n",
    "\n",
    "* Однако, для initial (non-reduced) vectors <b>Random Forest</b> опережает остальные модели (90% accuracy score).<br><br>\n",
    "\n",
    "* Интересно, что при inital vectors <b>Random Forest, Decision Tree</b>, и <b>Bayes</b> справляются довольно неплохо (81-90% accuracy), а для reduced vectors <b>Random Forest</b> и <b>Decision</b> резко ухудшают свои результаты (58-73% accuracy). В то же время, при reduced vectors <b>Bayes</b> работает одинаково хорошо при Tf/idf & Count Vectorizers (85% accuracy).<br><br>\n",
    "\n",
    "* В среднем, Tf/idf дает лучшие результаты для 3 моделей.<br><br>\n",
    "\n",
    "<b>е.</b> по 5 примеров ваших собственных на каждое значение (не из датасета) - результат применения к ним лучшего метода - <b>Random Forest + Tf/idf + Initial vectors</b><br><br>\n",
    "```\n",
    "1  они объездили всю Европу чтобы посетить самые знаменитые средневековые замки\n",
    "1  ночью замок был освещен и был открыт для посетителей и ночных экскурсий\n",
    "1  в подвалах и башнях старого замка было жутко холодно темно и страшновато\n",
    "1  чтобы завоевать замок нужно было штурмовать еще и ближайшие деревни\n",
    "1  в одной из башен замка освещенное окошко служило маяком слабой надежды\n",
    "0  я могу взломать любой замок особенно если нужен не ключ а числовая комбинация\n",
    "0  хозяева установили новые металлические замки с системой сигнализации\n",
    "0  я не заметил замка на двери и врезался в нее почти с разбега\n",
    "0  компания предлагает большой выбор замков оптом и с гарантией на четыре года\n",
    "0  ребенок пытался вставить карандаш в скважину замка и громко орал\n",
    "\n",
    "```\n",
    "<b>Результат: 8/10</b> (ошибочная классификация примеров 2 и 10):\n",
    "```\n",
    "'ночью замок был освещен и был открыт для посетителей и ночных экскурсий'\n",
    "'ребенок пытался вставить карандаш в скважину замка и громко орал'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "from pprint import pprint\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'этому', 'нам', 'будет', 'два', 'моего', 'того', 'вам', 'своем', 'всею', 'она', 'была', 'и', 'которой', 'моею', 'своя', 'моими', 'кому', 'этими', 'одна', 'таким', 'своему', 'было', 'нем', 'себя', 'можешь', 'моей', 'только', 'этим', 'может', 'быть', 'нею', 'кем', 'наша', 'так', 'моëм', 'могла', 'могли', 'ним', 'таких', 'эту', 'нашим', 'своих', 'вас', 'ее', 'одними', 'даже', 'ему', 'с', 'моим', 'тот', 'нас', 'своей', 'что-то', 'эта', 'его', 'мою', 'свои', 'пока', 'едва', 'наши', 'одного', 'всю', 'вами', 'одной', 'вы', 'были', 'будут', 'всеми', 'ей', 'тебя', 'моем', 'которому', 'всего', 'ещë', 'которым', 'ними', 'моему', 'такою', 'нашу', 'каждый', 'на', 'могут', 'тобой', 'уже', 'этом', 'такому', 'наших', 'главный', 'будь', 'свою', 'собою', 'когда', 'которые', 'я', 'мною', 'ней', 'тобою', 'который', 'мой', 'мое', 'той', 'мои', 'своё', 'в', 'могу', 'такое', 'всех', 'есть', 'моя', 'здесь', 'что', 'не', 'по', 'которого', 'него', 'чего', 'будем', 'еë', 'мной', 'себе', 'одно', 'ими', 'самый', 'одном', 'их', 'одних', 'одному', 'восемь', 'мне', 'во', 'рамка', 'стать', 'кого', 'наш', 'чему', 'мог', 'такими', 'оно', 'тех', 'то', 'один', 'как', 'этих', 'нашем', 'мочь', 'нашей', 'которых', 'эти', 'одну', 'это', 'свое', 'всей', 'такую', 'вся', 'кто', 'одною', 'свой', 'над', 'весь', 'всему', 'этой', 'нашею', 'ком', 'такие', 'своими', 'все', 'тем', 'по-прежнему', 'этот', 'тебе', 'нему', 'будешь', 'которою', 'он', 'после', 'год', 'своею', 'они', 'них', 'всем', 'нами', 'та', 'тому', 'нашими', 'можете', 'ту', 'ею', 'меня', 'те', 'со', 'этою', 'такой', 'тою', 'такая', 'всë', 'нашего', 'этого', 'без', 'будьте', 'ты', 'которая', 'наше', 'одни', 'был', 'примечательно', 'таком', 'том', 'а', 'сам', 'нее', 'котором', 'которую', 'еще', 'теми', 'своего', 'могло', 'четыре', 'им', 'собой', 'можем', 'первый', 'нём', 'чем', 'такого', 'лишь', 'кто-то', 'моë', 'которое', 'которыми', 'своим', 'ещё', 'одним', 'моих', 'нашему', 'буду', 'ли', 'неё', 'мы', 'своём'}\n"
     ]
    }
   ],
   "source": [
    "def load_stop_words(stop_filename):\n",
    "\t''' загрузить список стоп-слов из файла, одно слово на строке '''\n",
    "\twith open(stop_filename, encoding = 'utf-8') as f:\n",
    "\t\tstopwords = [w.strip() for w in f.readlines() if w.strip()]\n",
    "\treturn set(stopwords)\n",
    "\n",
    "stopw = \"stoplist_russian.txt\"\n",
    "print(load_stop_words(stopw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Препроцессинг, лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "с виду воду которая бьёт рядом с французским городом Авен\n",
      "['с', 'вид', 'вода', 'который', 'бить', 'рядом', 'с', 'французский', 'город', 'авен']\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(raw_text):\n",
    "    clean_text = re.sub('\\W+', ' ', raw_text) # \\W = [^a-zA-Z0-9_]\n",
    "    return clean_text\n",
    "\n",
    "def lemmatize(input):\n",
    "    return [lemma.strip() for lemma in m.lemmatize(preprocessing(input.lower())) if lemma.strip()]\n",
    "\n",
    "text = \"с виду воду, которая бьёт  рядом с французским городом Авен\"\n",
    "m.lemmatize(text)\n",
    "\n",
    "#r_text = \"Он еле дождался, пока я доковыряюсь ключом в замке и, не снимая сапожек, прямиком пошёл в свою спальню.\"\n",
    "print(preprocessing(text))\n",
    "print(lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Он еле дождался доковыряюсь ключом замке снимая\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(lemmas, stopwords):\n",
    "    return ' '.join([word for word in lemmas if word not in stopwords])\n",
    "\n",
    "#stop_words_filename = 'D:/GooDrive/0_2018_Edu_CL2/0_2018_Edu_HSE_Bak_CL2/WSD/WSD_Classifier/stoplist_russian.txt' \t# одно слово на строке\n",
    "stop_words = load_stop_words(stopw)\n",
    "raw_texts = ['Он', 'еле', 'дождался', 'пока', 'я', 'доковыряюсь', 'ключом', 'в', 'замке', 'и', 'не', 'снимая']\n",
    "print(remove_stop_words(raw_texts, stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Найти наиболее частотные слова в корпусе (for reduced vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "f1 = open('context_words.txt', 'r', encoding = 'utf-8')\n",
    "text = f1.read()\n",
    "text = text.strip('\\n')\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "text = ''.join(ch for ch in text if ch not in exclude)\n",
    "text = text.split(' ')\n",
    "\n",
    "# remove stop-words\n",
    "text = remove_stop_words(text, stop_words)\n",
    "\n",
    "# lemmatize\n",
    "text = lemmatize(text)\n",
    "\n",
    "# counter\n",
    "counts = Counter(text)\n",
    "counts = sorted(counts.items(), key=lambda pair: pair[1], reverse=True)\n",
    "\n",
    "# list of most popular words\n",
    "popular = []\n",
    "\n",
    "for i in counts:\n",
    "    if i[1] > 10:\n",
    "        popular.append(i[0])\n",
    "\n",
    "print(len(popular))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка и адаптация корпуса (initial vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def remove_stop_words(lemmas, stopwords):\n",
    "    return ' '.join([word for word in lemmas if word not in stopwords])\n",
    "\n",
    "def load_files(filename):\n",
    "    # список, где будут накапливаться результаты\n",
    "    results = []\n",
    "    \n",
    "    # открываем файл как переменную inp_file.\n",
    "    # Важно помнить, что в этой переменной хранится не сам текстовый файл, а своего рода указатель на него.\n",
    "    # Файл еще предстоит прочитать.\n",
    "    # Конструкция with следит за тем, чтобы переменная, которая после as, существовала только внутри блока.\n",
    "    # Благодаря этому файл закроется сразу же после использования\n",
    "    with(codecs.open(filename, encoding = 'utf-8')) as inp_file:\n",
    "        # читаем первую строку \"в никуда\" (не сохраняем результат).\n",
    "        # Первая строка у нас — это названия колонок, они нам не нужны\n",
    "        inp_file.readline()\n",
    "        # Для каждой строки в файле\n",
    "        for line in inp_file:\n",
    "            # откусываем концы строк\n",
    "            line = line.strip('\\r\\n')\n",
    "            # строка.count(подстрока) возвращает количество вхождений подстроки в строку\n",
    "            if line.count('\\t') != 1:\n",
    "            # специальное ключевое слово для перехода к следующей итерации цикла\n",
    "                continue\n",
    "            # делим строку по табуляции и складываем в каждую из двух переменных очередное значение\n",
    "            sence, context = line.split('\\t')\n",
    "            # добавляем кортеж (sence, context) в общий список результатов\n",
    "            \n",
    "            cx = lemmatize(context)\n",
    "            #cx = context\n",
    "            cx = remove_stop_words(cx, stop_words)\n",
    "            results.append((int(sence), cx))\n",
    "    # возвращаем результаты в виде списка кортежей (sence, context)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка и адаптация корпуса для уменьшенной размерности вектора (reduced vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def remove_stop_words(lemmas, stopwords): # also removes popular words\n",
    "    return ' '.join([word for word in lemmas if word not in stopwords and word not in popular])\n",
    "\n",
    "def load_files(filename):\n",
    "    # список, где будут накапливаться результаты\n",
    "    results = []\n",
    "    \n",
    "    with(codecs.open(filename, encoding = 'utf-8')) as inp_file:\n",
    "        inp_file.readline()\n",
    "        for line in inp_file:\n",
    "            line = line.strip('\\r\\n')\n",
    "            if line.count('\\t') != 1:\n",
    "                continue\n",
    "            sence, context = line.split('\\t')  \n",
    "            cx = lemmatize(context)\n",
    "            # remove most popular words + stop words\n",
    "            cx = remove_stop_words(cx, stop_words)\n",
    "                    \n",
    "            results.append((int(sence), cx))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# указываем абсолютный или относительный путь\n",
    "data = load_files('castle-lock.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('lemmatized_data.txt', mode='w', encoding='utf-8') as wr:\n",
    "    wr.write('sense\\tcontext(lemmatized)\\r\\n')\n",
    "    for item in data:\n",
    "        wr.write(str(item[0]) + '\\t' + item[1] + \"\\r\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Перевод корпуса в векторы признаков, feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# математика\n",
    "import numpy\n",
    "\n",
    "# разные классификаторы\n",
    "from sklearn.naive_bayes import MultinomialNB       # Multinomial Naive Bayes\n",
    "#from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier     # Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest\n",
    "#from sklearn.svm import LinearSVC\n",
    "\n",
    "# векторизация\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# деление корпуса train/test\n",
    "from sklearn.model_selection import cross_val_score # cross-validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['горный склон конный спорт рыбалка круиз исторический место пляжный', 'принцесса башня смело спасать распрекрасный за уносить жить', 'например сыграть роль огонь сказочный или светлячок летний сад для модный', 'из семь чудо свет величественный святой петр xv сегодня замок располагать', 'замок святой петр xv сегодня располагать музей подводный археология']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x_context = [item[1] for item in data]\n",
    "y_labels = [item[0] for item in data]\n",
    "print(x_context[:5])\n",
    "print(y_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(input):\n",
    "    return input.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classifiers = [('SVM', LinearSVC), ('Bayes', MultinomialNB)]\n",
    "classifiers = [('Bayes', MultinomialNB), ('Decision Tree', DecisionTreeClassifier), ('Random Forest', RandomForestClassifier)]\n",
    "vectorizers = [('Counts', CountVectorizer), ('TfIdf', TfidfVectorizer)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-score for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_classifier(clf, metric='f1'):\n",
    "    scores = cross_val_score(pipeline, numpy.asarray(x_context), numpy.asarray(y_labels), cv=5, scoring=metric)\n",
    "    score = sum(scores) / len(scores)    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline score estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes Counts 0.89708488045\n",
      "Bayes TfIdf 0.889761477254\n",
      "Decision Tree Counts 0.812041803886\n",
      "Decision Tree TfIdf 0.78332810719\n",
      "Random Forest Counts 0.840131155158\n",
      "Random Forest TfIdf 0.811500298455\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    for vctr in vectorizers:\n",
    "        pipeline = Pipeline([\n",
    "    ('vectorizer', vctr[1]()),\n",
    "    ('classifier', clf[1]()) ])\n",
    "        print (clf[0], vctr[0], score_classifier(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn.feature_extraction.text import BinaryVectorizer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import os, sys, codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "горный склон конный спорт рыбалка круиз исторический место пляжный\n",
      "принцесса башня смело спасать распрекрасный за уносить жить\n",
      "например сыграть роль огонь сказочный или светлячок летний сад для модный\n",
      "из семь чудо свет величественный святой петр xv сегодня замок располагать\n",
      "замок святой петр xv сегодня располагать музей подводный археология\n",
      "прибор вешать большой зал дворец масштабный фамильный имение совместно\n",
      "размер первоначальный выборгский основывать семь рано же\n",
      "информация о товар конструктор рыцарский 2700 руб фантастический набор деревянный\n",
      "другой можно возводить настоящий рыцарский упаковка или придумывать игра\n",
      "например находиться руины девичий 110 километр от измир располагать\n",
      "259804224\n"
     ]
    }
   ],
   "source": [
    "texts = [item[1] for item in data]\n",
    "for i in range(10):\n",
    "    print (texts[i])\n",
    "    \n",
    "len(texts)\n",
    "\n",
    "print (3974 *16344 * 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization: Tf idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 828)\t0.30657838977\n",
      "  (0, 3259)\t0.35877136719\n",
      "  (0, 1543)\t0.35877136719\n",
      "  (0, 3418)\t0.35877136719\n",
      "  (0, 3125)\t0.35877136719\n",
      "  (0, 1626)\t0.35877136719\n",
      "  (0, 1366)\t0.292911162426\n",
      "  (0, 1815)\t0.218886679261\n",
      "  (0, 2499)\t0.35877136719 (1, 4149)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer() # Tf idf\n",
    "\n",
    "texts = [item[1] for item in data]\n",
    "vectorized = vectorizer.fit_transform(texts)\n",
    "vectorized\n",
    "\n",
    "print (vectorized[0], vectorized[0].shape)\n",
    "print('\\n')\n",
    "\n",
    "names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = [item[0] for item in data]\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized, y_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 140\n",
      "Right: 124\n",
      "Score: 0.886\n"
     ]
    }
   ],
   "source": [
    "items = clf.predict(X_test.toarray())\n",
    "right = 0\n",
    "for i in range(len(items)):\n",
    "    if items[i] == y_test[i]:\n",
    "        right += 1\n",
    "        \n",
    "print ('Total: %d\\nRight: %d\\nScore: %.3f' % (len(items), right, float(right) / len(items)))\n",
    "\n",
    "words = {}\n",
    "for i in range(len(clf.feature_importances_)):\n",
    "    words[names[i]] = clf.feature_importances_[i]\n",
    "    \n",
    "#for item in sorted(words, key = lambda word: words[word], reverse=True):\n",
    "#    print (item, words[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf idf & Random forest f-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90361445783132521"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, items, labels=None, pos_label=1, average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier: Multinomial naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = [item[0] for item in data]\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized, y_labels, test_size=0.1, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 140\n",
      "Right: 124\n",
      "Score: 0.886\n"
     ]
    }
   ],
   "source": [
    "items = clf.predict(X_test.toarray())\n",
    "right = 0\n",
    "for i in range(len(items)):\n",
    "    if items[i] == y_test[i]:\n",
    "        right += 1\n",
    "        \n",
    "print ('Total: %d\\nRight: %d\\nScore: %.3f' % (len(items), right, float(right) / len(items)))\n",
    "\n",
    "#words = {}\n",
    "#for i in range(len(clf.feature_importances_)):\n",
    "#    words[names[i]] = clf.feature_importances_[i]     # no feature_importances_ in MultinomialNB\n",
    "    \n",
    "#for item in sorted(words, key = lambda word: words[word], reverse=True):\n",
    "#    print (item, words[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf idf & multinomial naive Bayes f-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8904109589041096"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, items, labels=None, pos_label=1, average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = [item[0] for item in data]\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized, y_labels, test_size=0.1, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 140\n",
      "Right: 111\n",
      "Score: 0.793\n"
     ]
    }
   ],
   "source": [
    "items = clf.predict(X_test.toarray())\n",
    "right = 0\n",
    "for i in range(len(items)):\n",
    "    if items[i] == y_test[i]:\n",
    "        right += 1\n",
    "        \n",
    "print ('Total: %d\\nRight: %d\\nScore: %.3f' % (len(items), right, float(right) / len(items)))\n",
    "\n",
    "words = {}\n",
    "for i in range(len(clf.feature_importances_)):\n",
    "    words[names[i]] = clf.feature_importances_[i]\n",
    "    \n",
    "#for item in sorted(words, key = lambda word: words[word], reverse=True):\n",
    "#    print (item, words[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf idf & Decision Tree f-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81987577639751552"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, items, labels=None, pos_label=1, average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization: Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2499)\t1\n",
      "  (0, 1815)\t1\n",
      "  (0, 1366)\t1\n",
      "  (0, 1626)\t1\n",
      "  (0, 3125)\t1\n",
      "  (0, 3418)\t1\n",
      "  (0, 1543)\t1\n",
      "  (0, 3259)\t1\n",
      "  (0, 828)\t1 (1, 4149)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer() # Count\n",
    "\n",
    "texts = [item[1] for item in data]\n",
    "vectorized = vectorizer.fit_transform(texts)\n",
    "vectorized\n",
    "\n",
    "print (vectorized[0], vectorized[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = [item[0] for item in data]\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized, y_labels, test_size=0.1, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 140\n",
      "Right: 119\n",
      "Score: 0.850\n"
     ]
    }
   ],
   "source": [
    "items = clf.predict(X_test.toarray())\n",
    "right = 0\n",
    "for i in range(len(items)):\n",
    "    if items[i] == y_test[i]:\n",
    "        right += 1\n",
    "    #print items[i], y_test[i]\n",
    "names = vectorizer.get_feature_names()\n",
    "words = {}\n",
    "print ('Total: %d\\nRight: %d\\nScore: %.3f' % (len(items), right, float(right) / len(items)))\n",
    "for i in range(len(clf.feature_importances_)):\n",
    "    words[names[i]] = clf.feature_importances_[i]\n",
    "    \n",
    "#for item in sorted(words, key = lambda word: words[word], reverse=True):\n",
    "#    print (item, words[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count & Random Forest f-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87272727272727268"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, items, labels=None, pos_label=1, average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier: Multinomial naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = [item[0] for item in data]\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized, y_labels, test_size=0.1, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 140\n",
      "Right: 123\n",
      "Score: 0.879\n"
     ]
    }
   ],
   "source": [
    "items = clf.predict(X_test.toarray())\n",
    "right = 0\n",
    "for i in range(len(items)):\n",
    "    if items[i] == y_test[i]:\n",
    "        right += 1\n",
    "        \n",
    "print ('Total: %d\\nRight: %d\\nScore: %.3f' % (len(items), right, float(right) / len(items)))\n",
    "\n",
    "#words = {}\n",
    "#for i in range(len(clf.feature_importances_)):\n",
    "#    words[names[i]] = clf.feature_importances_[i]     # no feature_importances_ in MultinomialNB\n",
    "    \n",
    "#for item in sorted(words, key = lambda word: words[word], reverse=True):\n",
    "#    print (item, words[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count & Multinomial naive Bayes f-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88435374149659862"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, items, labels=None, pos_label=1, average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = [item[0] for item in data]\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized, y_labels, test_size=0.1, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 140\n",
      "Right: 110\n",
      "Score: 0.786\n"
     ]
    }
   ],
   "source": [
    "items = clf.predict(X_test.toarray())\n",
    "right = 0\n",
    "for i in range(len(items)):\n",
    "    if items[i] == y_test[i]:\n",
    "        right += 1\n",
    "        \n",
    "print ('Total: %d\\nRight: %d\\nScore: %.3f' % (len(items), right, float(right) / len(items)))\n",
    "\n",
    "words = {}\n",
    "for i in range(len(clf.feature_importances_)):\n",
    "    words[names[i]] = clf.feature_importances_[i]\n",
    "    \n",
    "#for item in sorted(words, key = lambda word: words[word], reverse=True):\n",
    "#    print (item, words[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Count & Decision Tree f-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, items, labels=None, pos_label=1, average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing 10 extra contexts (Initial vectors + Tf idf + Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer() # Tf idf\n",
    "\n",
    "test_data = load_files('test_contexts.txt') # includes 10 extra contexts\n",
    "test_data1 = [item[1] for item in test_data]\n",
    "\n",
    "vectorized = vectorizer.fit_transform(test_data1)\n",
    "print(vectorized.shape[0])\n",
    "\n",
    "v = vectorized.toarray()\n",
    "\n",
    "v1 = v[:1400]      # for training\n",
    "v2 = v[1400:1410]  # 10 test sentences\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=250)\n",
    "y_labels = [item[0] for item in test_data[:1400]]\n",
    "\n",
    "y_labels = [item[0] for item in test_data[:1400]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(v1, y_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 140\n",
      "Right: 123\n",
      "Score: 0.879\n"
     ]
    }
   ],
   "source": [
    "items = clf.predict(X_test)\n",
    "right = 0\n",
    "for i in range(len(items)):\n",
    "    if items[i] == y_test[i]:\n",
    "        right += 1\n",
    "        \n",
    "print ('Total: %d\\nRight: %d\\nScore: %.3f' % (len(items), right, float(right) / len(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89820359281437123"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, items, labels=None, pos_label=1, average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "test_items = clf.predict(v2)\n",
    "for i in test_items:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Первые 5 примеров -- 1 (castle), последние 5 -- 0 (lock)\n",
    "* <b>Результат: 8/10</b> (ошибочная классификация примеров 2 и 10):\n",
    "* 2 -- 'ночью замок был освещен и был открыт для посетителей и ночных экскурсий'\n",
    "* 10 -- 'ребенок пытался вставить карандаш в скважину замка и громко орал'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
