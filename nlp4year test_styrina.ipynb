{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Вариант 2. Соня Стырина\n",
    "\n",
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(a, b):\n",
    "    \"\"\"dice coefficient 2nt/na + nb.\"\"\"\n",
    "    a_bigrams = set(a)\n",
    "    b_bigrams = set(b)\n",
    "    overlap = len(a_bigrams & b_bigrams)\n",
    "    return overlap * 2.0/(len(a_bigrams) + len(b_bigrams))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'оно оказалось не самым острым лезвием и я сумел не порезаться'\n",
    "s2 = 'мы нащупали острые штыри торчащие вдоль всей стены'\n",
    "s3 = 'мама любила готовить острый шашлык где было больше перца чем мяса'\n",
    "s4 = 'без острого соуса колбаски были не такими вкусными'\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "lemmas1 = m.lemmatize(s1)\n",
    "lemmas2 = m.lemmatize(s2)\n",
    "lemmas3 = m.lemmatize(s3)\n",
    "lemmas4 = m.lemmatize(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2727272727272727\n",
      "0.24\n",
      "0.36363636363636365\n",
      "0.2608695652173913\n",
      "0.3\n",
      "0.34782608695652173\n"
     ]
    }
   ],
   "source": [
    "a = dice_coefficient(lemmas1, lemmas2)\n",
    "b = dice_coefficient(lemmas1, lemmas3)\n",
    "c = dice_coefficient(lemmas1, lemmas4)\n",
    "d = dice_coefficient(lemmas2, lemmas3)\n",
    "e = dice_coefficient(lemmas2, lemmas4)\n",
    "f = dice_coefficient(lemmas3, lemmas4)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "упорядоченные по близости:\n",
    "\n",
    "1 & 4: 0.36363636363636365\n",
    "\n",
    "3 & 4: 0.34782608695652173\n",
    "\n",
    "2 & 4: 0.3\n",
    "\n",
    "1 & 2: 0.2727272727272727\n",
    "\n",
    "2 & 3: 0.2608695652173913\n",
    "\n",
    "1 & 3: 0.24\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Sofia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Вар. 2. Задание на WordNet\n",
    "# + 1) Найти все значения (синсеты) для лексемы bass,\n",
    "# + 2) найти гиперонимы для значения лексемы bass - fish,\n",
    "# + 3) вычислите одним из сопобов расстояние: (bass, fish), (fish, vertebrate (позвоночное)).\n",
    "# Какое расстояние меньше. Соответствует ли это Вашей интуиции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.01')\n",
      "Synset('bass.n.02')\n",
      "Synset('bass.n.03')\n",
      "Synset('sea_bass.n.01')\n",
      "Synset('freshwater_bass.n.01')\n",
      "Synset('bass.n.06')\n",
      "Synset('bass.n.07')\n",
      "Synset('bass.n.08')\n",
      "Synset('bass.s.01')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "all_fish = wordnet.synsets('bass')\n",
    "\n",
    "for a in all_fish:\n",
    "    print(a)\n",
    "    \n",
    "# all fish:\n",
    "# Synset('sea_bass.n.01')\n",
    "# Synset('freshwater_bass.n.01')\n",
    "# Synset('bass.n.08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the lowest part of the musical range\n",
      "the lowest part in polyphonic music\n",
      "an adult male singer with the lowest voice\n",
      "the lean flesh of a saltwater fish of the family Serranidae\n",
      "any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n",
      "the lowest adult male singing voice\n",
      "the member with the lowest range of a family of musical instruments\n",
      "nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes\n",
      "having or denoting a low vocal or instrumental range\n"
     ]
    }
   ],
   "source": [
    "for i in wordnet.synsets('bass'):\n",
    "    print(i.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('saltwater_fish.n.01')]\n",
      "[Synset('freshwater_fish.n.01')]\n",
      "[Synset('percoid_fish.n.01')]\n"
     ]
    }
   ],
   "source": [
    "all_fish_1 = [all_fish[3], all_fish[4], all_fish[7]]\n",
    "\n",
    "for f in all_fish_1:\n",
    "    print(f.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('percoid_fish.n.01')\n"
     ]
    }
   ],
   "source": [
    "bass = wordnet.synset('percoid_fish.n.01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any of various mostly cold-blooded aquatic vertebrates usually having scales and breathing through gills\n",
      "the flesh of fish used as food\n",
      "(astrology) a person who is born while the sun is in Pisces\n",
      "the twelfth sign of the zodiac; the sun is in this sign from about February 19 to March 20\n",
      "seek indirectly\n",
      "catch or try to catch fish or shellfish\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Synset('fish.n.01')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fishes = wordnet.synsets('fish')\n",
    "for i in fishes:\n",
    "    print(i.definition())\n",
    "    \n",
    "fish = fishes[0]\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animals having a bony or cartilaginous skeleton with a segmented spinal column and a large brain enclosed in a skull or cranium\n",
      "having a backbone or spinal column\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Synset('vertebrate.n.01')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertebrates = wordnet.synsets('vertebrate')\n",
    "for v in vertebrates:\n",
    "    print(v.definition())\n",
    "\n",
    "vertebrate = vertebrates[0]\n",
    "vertebrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bass.path_similarity(fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish.path_similarity(vertebrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bass - fish -- меньшее расстояние.\n",
    "совпадает с интуицией: если спросить обычного носителя 'what is bass?', он чаще ответит 'it's a kind of fish', чем 'it's a kind of vertebrate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# + Возьмите готовую модель word2vec (см. последнее практическое занятие).\n",
    "# + Вычислите топ 10 слов для слова \"привести\".\n",
    "# Определите топ 5 близких к слову \"привести\" по русскому ворд-нету:\n",
    "# http://ruwordnet.ru/en/\n",
    "# или по РуТез http://www.labinform.ru/pub/ruthes/(любым способом, опишите, как Вы искали близкие слова).\n",
    "# Каков процент пересечения?\n",
    "# Какие, полученные в выбранной Вами модели слова, на Ваш взгляд, попали в топ 10 близких ошибочно.\n",
    "# Попробуйте прокомментировать, почему\n",
    "\n",
    "import sys\n",
    "import gensim, logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = 'text.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-05 14:32:59,418 : INFO : collecting all words and their counts\n",
      "2018-03-05 14:32:59,421 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-05 14:32:59,510 : INFO : collected 30172 word types from a corpus of 68570 raw words and 5432 sentences\n",
      "2018-03-05 14:32:59,511 : INFO : Loading a fresh vocabulary\n",
      "2018-03-05 14:32:59,548 : INFO : min_count=2 retains 6793 unique words (22% of original 30172, drops 23379)\n",
      "2018-03-05 14:32:59,550 : INFO : min_count=2 leaves 45191 word corpus (65% of original 68570, drops 23379)\n",
      "2018-03-05 14:32:59,582 : INFO : deleting the raw counts dictionary of 30172 items\n",
      "2018-03-05 14:32:59,586 : INFO : sample=0.001 downsamples 34 most-common words\n",
      "2018-03-05 14:32:59,588 : INFO : downsampling leaves estimated 37321 word corpus (82.6% of prior 45191)\n",
      "2018-03-05 14:32:59,589 : INFO : estimated required memory for 6793 words and 500 dimensions: 30568500 bytes\n",
      "2018-03-05 14:32:59,623 : INFO : resetting layer weights\n",
      "2018-03-05 14:32:59,802 : INFO : training model with 3 workers on 6793 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-03-05 14:33:00,424 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-05 14:33:00,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-05 14:33:00,445 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-05 14:33:00,447 : INFO : training on 342850 raw words (186553 effective words) took 0.6s, 290297 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(data, size=500, window=10, min_count=2, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-05 14:33:28,241 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6793\n"
     ]
    }
   ],
   "source": [
    "print(len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-05 14:33:46,773 : INFO : saving Word2Vec object under my.model, separately None\n",
      "2018-03-05 14:33:46,776 : INFO : not storing attribute syn0norm\n",
      "2018-03-05 14:33:46,780 : INFO : not storing attribute cum_table\n",
      "2018-03-05 14:33:47,570 : INFO : saved my.model\n"
     ]
    }
   ],
   "source": [
    "model.save('my.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-05 14:34:51,011 : INFO : loading projection weights from ruscorpora_mystem_cbow_300_2_2015.bin.gz\n",
      "2018-03-05 14:35:19,959 : INFO : loaded (281776, 300) matrix from ruscorpora_mystem_cbow_300_2_2015.bin.gz\n"
     ]
    }
   ],
   "source": [
    "#m = 'ruscorpora_1_300_10.bin.gz'\n",
    "m = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
    "if m.endswith('.vec.gz'):\n",
    "    #model = gensim.models.Word2Vec.load_word2vec_format(m, binary=False)\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "elif m.endswith('.bin.gz'):\n",
    "    #model = gensim.models.Word2Vec.load_word2vec_format(m, binary=True)\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "else:\n",
    "    model = gensim.models.Word2Vec.load(m)\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-05 14:35:30,450 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = ['привести_V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "привести_V is not present in the model\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    # есть ли слово в модели? Может быть, и нет\n",
    "    if word in model:\n",
    "        print(word)\n",
    "        # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n",
    "        print(model[word][:10])\n",
    "        # выдаем 10 ближайших соседей слова:\n",
    "        for i in model.most_similar(positive=[word], topn=10):\n",
    "            # слово + коэффициент косинусной близости\n",
    "            print(i[0], i[1])\n",
    "        print('\\n')\n",
    "    else:\n",
    "        # Увы!\n",
    "        print(word + ' is not present in the model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = ['приводить_V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "приводить_V\n",
      "[ 0.01666277  0.06401347 -0.02525937 -0.05258781 -0.0178264  -0.11472266\n",
      "  0.0342095   0.05577536  0.03680634 -0.03717699]\n",
      "приводиться_V 0.596032440662384\n",
      "повлечь_V 0.5241738557815552\n",
      "последовать_V 0.5113583207130432\n",
      "сопровождаться_V 0.5028162002563477\n",
      "вызывать_V 0.5005214214324951\n",
      "являться_V 0.4616868197917938\n",
      "проиллюстрировать_V 0.4534916281700134\n",
      "ссылаться_V 0.4523410201072693\n",
      "приходить_V 0.44602423906326294\n",
      "свидетельствовать_V 0.442598432302475\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    # есть ли слово в модели? Может быть, и нет\n",
    "    if word in model:\n",
    "        print(word)\n",
    "        # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n",
    "        print(model[word][:10])\n",
    "        # выдаем 10 ближайших соседей слова:\n",
    "        for i in model.most_similar(positive=[word], topn=10):\n",
    "            # слово + коэффициент косинусной близости\n",
    "            print(i[0], i[1])\n",
    "        print('\\n')\n",
    "    else:\n",
    "        # Увы!\n",
    "        print(word + ' is not present in the model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# + Определите топ 5 близких к слову \"привести\" по русскому ворд-нету:\n",
    "# + http://ruwordnet.ru/en/\n",
    "# + (любым способом, опишите, как Вы искали близкие слова).\n",
    "# Каков процент пересечения?\n",
    "# Какие, полученные в выбранной Вами модели слова, на Ваш взгляд, попали в топ 10 близких ошибочно.\n",
    "# Попробуйте прокомментировать, почему"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интуитивно наиболее близкие иперонимы & гипонимы (http://ruwordnet.ru/en/search/привести):\n",
    "\n",
    "ОБОСНОВАТЬ\n",
    "\n",
    "ПРЕДСТАВИТЬ (ДОКАЗАТЕЛЬСТВО)\n",
    "\n",
    "СОСЛАТЬСЯ\n",
    "\n",
    "ЗАЩИТИТЬ (ТОЧКУ ЗРЕНИЯ)\n",
    "\n",
    "ОТСТОЯТЬ (ПОЗИЦИЮ)\n",
    "\n",
    "Из word2vec совпадает только 'ссылаться_V', но 'проиллюстрировать_V' довольно близко к ОБОСНОВАТЬ & ПРЕДСТАВИТЬ ДОКАЗАТЕЛЬСТВО.\n",
    "\n",
    "Ошибочная выдача word2vec:\n",
    "\n",
    "повлечь_V -- has to do more with consequences, rather than proof? может следовало бы здесь выдать 'привлечь' (e.g. 'привлечь к делу')\n",
    "\n",
    "являться_V -- совсем непонятно, как это связано\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "крик_S\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match('слово_S рассказ_S мнение_S крик_S'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
